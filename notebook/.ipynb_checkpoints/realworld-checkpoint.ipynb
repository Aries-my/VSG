{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<module 'Generation' from 'D:\\\\netSVG\\\\Generation.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "import dataset\n",
    "import config, plotting, sample, SampleCharacter, XLim, QRselection\n",
    "import QrModels, Point\n",
    "import copy\n",
    "import RelativeImportance\n",
    "import Measure\n",
    "import Generation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "importlib.reload(config)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(sample)\n",
    "importlib.reload(SampleCharacter)\n",
    "importlib.reload(XLim)\n",
    "importlib.reload(QRselection)\n",
    "importlib.reload(QrModels)\n",
    "importlib.reload(Point)\n",
    "importlib.reload(RelativeImportance)\n",
    "importlib.reload(Measure)\n",
    "importlib.reload(Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../figures/MLCC already exists replacing files in this notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_config = config.DatasetConfig(scenario=\"MLCC\", n_instance=1000)\n",
    "\n",
    "assert(dataset_config.scenario == \"PG\" \n",
    "       or dataset_config.scenario == \"PT\"\n",
    "      or dataset_config.scenario == \"MLCC\"\n",
    "      )\n",
    "fig_dir = f\"../figures/{dataset_config.scenario}\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(fig_dir)\n",
    "    print(f\"Directory {fig_dir} created \") \n",
    "except FileExistsError:\n",
    "    print(f\"Directory {fig_dir} already exists replacing files in this notebook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name_test = \"../data/\" + dataset_config.scenario+ \"/test_data.txt\"\n",
    "X_test,Y_test = dataset.get_functional_test_data(file_name_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name_train = \"../data/\" + dataset_config.scenario+ \"/train_data.txt\"\n",
    "X_train,Y_train = dataset.get_functional_train_data(file_name_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 1985\n",
    "if dataset_config.scenario == \"PG\" :\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, lr_disc=0.001, dec_gen=0, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )\n",
    "    \n",
    "elif dataset_config.scenario == \"PT\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, lr_disc=0.0005, dec_gen=0, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )\n",
    "elif dataset_config.scenario == \"MLCC\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, lr_disc=0.0005, dec_gen=0, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstandardized regression coefficient: \n",
      "[ 5.16265980e+02 -5.93944373e+03  3.15860370e+03 -1.34158736e+04\n",
      "  1.26865032e+04  1.49033300e+01  1.26763000e+00 -1.69634700e+01\n",
      "  1.58286887e+03  2.22348900e+01  7.31887390e+02 -8.24578380e+02]\n",
      "normal coefficient: \n",
      "120120.5083\n",
      "Standardized regression coefficient: \n",
      "[ 0.0989  -0.656    0.08608 -0.42259  0.37176  0.25209  0.66808 -0.11532\n",
      "  0.99639  0.12254  0.78234 -0.06253]\n",
      "normal coefficient: \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "coef = sample.get_sta_reg_cov(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The importance for every dimension:\n",
      "[0.005807103724392776, 0.08056379800289575, 0.027708178275372558, 0.029279516948187895, 0.06921072266530037, 0.1222271387246593, 0.11319916571268794, 0.04157214482892202, 0.12625181040975142, 0.06501790211941245, 0.3118271249994784, 0.0073353935889390945]\n"
     ]
    }
   ],
   "source": [
    "if dataset_config.scenario == \"PG\" :\n",
    "    imp = RelativeImportance.relativeImp_PG()\n",
    "elif dataset_config.scenario == \"PT\":\n",
    "    imp = RelativeImportance.relativeImp_PT()\n",
    "#elif dataset_config.scenario == \"MLCC\":\n",
    "     #imp = RelativeImportance.relativeImp_MLCC()\n",
    "imp = [0.005807103724392776, 0.08056379800289575, 0.027708178275372558, 0.029279516948187895, 0.06921072266530037, 0.1222271387246593, 0.11319916571268794, 0.04157214482892202, 0.12625181040975142, 0.06501790211941245, 0.3118271249994784, 0.0073353935889390945]\n",
    "#imp = list(imp.values())\n",
    "print(\"The importance for every dimension:\")\n",
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance in x domain：\n",
      "minist dist:\n",
      "66.461\n",
      "maxist imp:\n",
      "0.3118271249994784\n",
      "The original length of the smaple: \n",
      "[ 1.23769 17.17089  5.90556  6.24046 14.75117 26.05077 24.1266   8.86044\n",
      " 26.90857 13.85753 66.461    1.56342]\n"
     ]
    }
   ],
   "source": [
    "length, max_dist = sample.get_sample_length(X_train,imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value area of x in the sample is between 2.7 and 3.3in the dimension of No. 0\n",
      "The value area of x in the sample is between 1.83 and 2.15in the dimension of No. 1\n",
      "The value area of x in the sample is between 0.92 and 1.0in the dimension of No. 2\n",
      "The value area of x in the sample is between 0.41 and 0.5in the dimension of No. 3\n",
      "The value area of x in the sample is between 0.0 and 0.08in the dimension of No. 4\n",
      "The value area of x in the sample is between 1262.0 and 1307.0in the dimension of No. 5\n",
      "The value area of x in the sample is between 10232.0 and 11750.0in the dimension of No. 6\n",
      "The value area of x in the sample is between 22.0 and 41.0in the dimension of No. 7\n",
      "The value area of x in the sample is between -75.6 and -73.5in the dimension of No. 8\n",
      "The value area of x in the sample is between 40.4 and 54.0in the dimension of No. 9\n",
      "The value area of x in the sample is between -9.0 and -5.2in the dimension of No. 10\n",
      "The value area of x in the sample is between 0.824 and 1.03in the dimension of No. 11\n",
      "The full length of every dimension:\n",
      "[   0.6      0.32     0.08     0.09     0.08    45.    1518.      19.\n",
      "    2.1     13.6      3.8      0.206]\n"
     ]
    }
   ],
   "source": [
    "x_min = np.amin(X_train, axis=0)\n",
    "x_max = np.amax(X_train, axis=0)\n",
    "L = sample.get_x_len(x_min, x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of diversions of the 0th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 1th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 2th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 3th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 4th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 5th dimension is: 2\n",
      "2\n",
      "The number of diversions of the 6th dimension is: 63\n",
      "63\n",
      "The number of diversions of the 7th dimension is: 3\n",
      "3\n",
      "The number of diversions of the 8th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 9th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 10th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 11th dimension is: 1\n",
      "1\n",
      "总的样方分割数为：\n",
      "378\n",
      "The number of diversions of the 0th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 1th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 2th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 3th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 4th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 5th dimension is: 2\n",
      "2\n",
      "The number of diversions of the 6th dimension is: 32\n",
      "32\n",
      "The number of diversions of the 7th dimension is: 2\n",
      "2\n",
      "The number of diversions of the 8th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 9th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 10th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 11th dimension is: 1\n",
      "1\n",
      "总的样方分割数为：\n",
      "128\n",
      "分割数：\n",
      "[ 1  1  1  1  1  2 32  2  1  1  1  1]\n",
      "样方的大小：\n",
      "[ 1.485228 20.605068  7.086672  7.488552 17.701404 31.260924 48.2532\n",
      " 10.632528 32.290284 16.629036 79.7532    1.876104]\n"
     ]
    }
   ],
   "source": [
    "n_sample,length = sample.divide_sample(length, L, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0维度，最小的x为2.7\n",
      "第0维度的中心值有：\n",
      "[3.44261]\n",
      "第1维度，最小的x为1.83\n",
      "第1维度的中心值有：\n",
      "[12.13253]\n",
      "第2维度，最小的x为0.92\n",
      "第2维度的中心值有：\n",
      "[4.46334]\n",
      "第3维度，最小的x为0.41\n",
      "第3维度的中心值有：\n",
      "[4.15428]\n",
      "第4维度，最小的x为0.0\n",
      "第4维度的中心值有：\n",
      "[8.8507]\n",
      "第5维度，最小的x为1262.0\n",
      "第5维度的中心值有：\n",
      "[1277.63046, 1308.89139]\n",
      "第6维度，最小的x为10232.0\n",
      "第6维度的中心值有：\n",
      "[10256.1266, 10304.3798, 10352.633, 10400.8862, 10449.1394, 10497.3926, 10545.6458, 10593.899, 10642.1522, 10690.4054, 10738.6586, 10786.9118, 10835.165, 10883.4182, 10931.6714, 10979.9246, 11028.1778, 11076.431, 11124.6842, 11172.9374, 11221.1906, 11269.4438, 11317.697, 11365.9502, 11414.2034, 11462.4566, 11510.7098, 11558.963, 11607.2162, 11655.4694, 11703.7226, 11751.9758]\n",
      "第7维度，最小的x为22.0\n",
      "第7维度的中心值有：\n",
      "[27.31626, 37.94879]\n",
      "第8维度，最小的x为-75.6\n",
      "第8维度的中心值有：\n",
      "[-59.45486]\n",
      "第9维度，最小的x为40.4\n",
      "第9维度的中心值有：\n",
      "[48.71452]\n",
      "第10维度，最小的x为-9.0\n",
      "第10维度的中心值有：\n",
      "[30.8766]\n",
      "第11维度，最小的x为0.824\n",
      "第11维度的中心值有：\n",
      "[1.76205]\n"
     ]
    }
   ],
   "source": [
    "dim = len(X_train[0])\n",
    "gen_x = sample.gen_x_center(dim,length,n_sample, x_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样方中心点：\n"
     ]
    }
   ],
   "source": [
    "gen_sample_point = sample.gen_product2(gen_x)\n",
    "print(\"样方中心点：\")\n",
    "gen_sample_point = np.array(gen_sample_point)\n",
    "#print(gen_sample_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "xlimit = []\n",
    "for index in range(len(n_sample)):\n",
    "    l = []\n",
    "    for i in range(n_sample[index]):\n",
    "        x = x_min[index] + i * length[index]\n",
    "        l.append(x)\n",
    "    l.append(x_min[index] + n_sample[index] * length[index])\n",
    "    xlimit.append(l)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_list = []\n",
    "xlim_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "x_value = []\n",
    "for index in range(dim):\n",
    "    xl = []\n",
    "    for i in range(len(X_train)):\n",
    "        x = X_train[i][index]\n",
    "        r = 0\n",
    "        for xi in xl:\n",
    "            if xi == x:\n",
    "                r = 1\n",
    "        if r == 0:\n",
    "            xl.append(x)\n",
    "    x_value.append(xl)\n",
    "    \n",
    "x_value_ori = copy.deepcopy(x_value)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "XLim.con_s(gen_sample_point, sample_list, dim, xlimit)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "XLim.con_sample(xlim_list, length, x_min, dim, n_sample)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "XLim.sample_feature(xlim_list, sample_list, x_value)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "XLim.add_xvalue(xlim_list)\n",
    "#os.exist(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_com, x_add = Generation.get_x_com(X_train, dim, x_value, x_value_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "E_dist = Generation.E_dist(x_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gen_x = []\n",
    "discard_list = []\n",
    "Generation.gen_x_sample(sample_list, X_train, gen_x, max_dist, dim, discard_list, x_com, x_max, x_min, E_dist)\n",
    "#gen_x_cross = sample.gen_product(x_value)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#f_list = []\n",
    "#sample.cross_point_del(gen_x_cross, X_train)\n",
    "#sample.point_filiter(gen_x_cross, X_train, max_dist, x_value, x_value_ori, dim, f_list)\n",
    "#print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_xlim = copy.deepcopy(xlimit)\n",
    "for index in range(dim):\n",
    "    i = len(plot_xlim[index])\n",
    "    plot_xlim[index][i-1] = x_max[index]\n",
    "print(\"over\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gen_x_checked = []\n",
    "XLim.check2(sample_list, xlim_list, gen_x_checked, discard_list, gen_x)\n",
    "XLim.sample_attri(sample_list, X_train, gen_x_checked, Y_train)\n",
    "XLim.xl_attri(xlim_list, X_train, gen_x_checked)\n",
    "gen_x = np.array(gen_x)\n",
    "#plotting.plot_genx(X_train, np.array(gen_x_checked), length, n_sample, exp_config, fig_dir, plot_xlim, \"gen_x_checked.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import GPy\n",
    "\n",
    "noise = 0.01\n",
    "length_ = 0.1\n",
    "\n",
    "run_hyperopt_search = True\n",
    "\n",
    "kernel = GPy.kern.RBF(input_dim=3, variance=noise, lengthscale=length_)\n",
    "gpr = GPy.models.GPRegression(X_train, Y_train.reshape(-1,1), kernel)\n",
    "if run_hyperopt_search:\n",
    "    gpr.optimize(messages=True) \n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gen_y_cross, cov_train_cross = gpr.predict(np.array(gen_x_checked))\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "XLim.add_y(sample_list, gpr)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "point_list = []\n",
    "Point.con_point(gen_x_checked, gen_y_cross, point_list)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for sample in sample_list:\n",
    "    for index in range(len(sample.gen_xlist)):\n",
    "        for point in point_list:\n",
    "            r = -1\n",
    "            for i in range(dim):\n",
    "                if point.x[i] != sample.gen_xlist[index][i]:\n",
    "                    r = 0\n",
    "                    break\n",
    "            if r == -1:\n",
    "                sample.points.append(point)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "qrX = X_train\n",
    "qrX = sm.add_constant(qrX[0:])\n",
    "qr = sm.QuantReg(Y_train.reshape(-1,1),qrX)\n",
    "res = qr.fit(q=.2)\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "quantiles = np.arange(.05, .96, .1)\n",
    "quantiles = np.around(quantiles, decimals=3)\n",
    "def fit_model(q):\n",
    "    res = qr.fit(q=q)\n",
    "    return q, np.around(res.params,decimals=  4)\n",
    "\n",
    "models = []\n",
    "\n",
    "for x in quantiles:\n",
    "    q, param = fit_model(x)\n",
    "    model = QrModels.QrModels(q, param[0], param[1:])\n",
    "    models.append(model)\n",
    "\n",
    "for model in models:\n",
    "    print(str(model.q)+'\\t'+str(model.a)+'\\t'+str(model.param))\n",
    "\n",
    "ols = sm.OLS(Y_train.reshape(-1,1),qrX).fit()\n",
    "           \n",
    "for ol in ols.params:\n",
    "    print(str(ol))\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if dataset_config.scenario == \"MLCC\":\n",
    "    y_quantile = [15676.750,16559.600,16657.000,17030.200,17143.350,17286.050,17342.350,17843.250,18193.950,18403.250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vir_xpoint = []\n",
    "vir_ypoint = []\n",
    "\n",
    "for xv in x_value:\n",
    "    xv.sort()\n",
    "for xv in x_value_ori:\n",
    "    xv.sort()\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "QRselection.qr_selection(xlim_list, models, vir_xpoint, vir_ypoint, y_quantile, ols, x_value_ori,\n",
    "                 n_sample, X_train, Y_train, sample_list, point_list, x_value)\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for point in point_list:\n",
    "    if point.checked == 1:\n",
    "        i += 1\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from hpelm import ELM\n",
    "elm = ELM(X_train, Y_train.reshape(-1,1))\n",
    "elm.add_neurons(20, \"sigm\")\n",
    "elm.add_neurons(10, \"rbf_l2\")\n",
    "elm.train(X_train, Y_train, \"LOO\")\n",
    "y_predict_output = elm.predict(X_test)\n",
    "\n",
    "test_list = []\n",
    "for i in range(len(X_test)):\n",
    "    point = Point.Point(X_test[i], y_predict_output[i])\n",
    "    point.true = Y_test[i]\n",
    "    point.erro = Y_test[i] - point.y\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotting.plot_erro(test_list, exp_config, fig_dir, \"erro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mae = Measure.mae1(test_list)\n",
    "mse = Measure.mse1(test_list)\n",
    "mape = Measure.mape1(test_list)\n",
    "print(\" all test point\")\n",
    "print(mae)\n",
    "print(mse)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(\"../figures/MLCC/vx_data.txt\", np.array(vir_xpoint),fmt='%.8f',delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"../figures/MLCC/vy_data.txt\", np.array(vir_ypoint),fmt='%.8f',delimiter=' ')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
