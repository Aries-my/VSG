{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\CondaEnv\\netSVGpython36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\CondaEnv\\netSVGpython36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\CondaEnv\\netSVGpython36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\CondaEnv\\netSVGpython36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\CondaEnv\\netSVGpython36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\CondaEnv\\netSVGpython36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/html": "\n    <div class=\"bk-root\">\n        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n        <span id=\"1001\">Loading BokehJS ...</span>\n    </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<module 'models.cgan_model' from 'D:\\\\netSVG\\\\models\\\\cgan_model.py'>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import importlib\n",
    "from models import cgan_model,cgan_model_real\n",
    "import dataset\n",
    "import config, plotting, sample, SampleCharacter, XLim, QRselection\n",
    "import QrModels, Point\n",
    "import copy\n",
    "import RelativeImportance\n",
    "import Measure\n",
    "import Generation\n",
    "\n",
    "\n",
    "importlib.reload(config)\n",
    "importlib.reload(dataset)\n",
    "importlib.reload(plotting)\n",
    "importlib.reload(sample)\n",
    "importlib.reload(SampleCharacter)\n",
    "importlib.reload(XLim)\n",
    "importlib.reload(QRselection)\n",
    "importlib.reload(QrModels)\n",
    "importlib.reload(Point)\n",
    "importlib.reload(RelativeImportance)\n",
    "importlib.reload(Measure)\n",
    "importlib.reload(Generation)\n",
    "importlib.reload(cgan_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Directory ../figures/MLCC already exists replacing files in this notebook\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os\n",
    "dataset_config = config.DatasetConfig(scenario=\"MLCC\", n_instance=1000)\n",
    "\n",
    "assert(dataset_config.scenario == \"PG\" \n",
    "       or dataset_config.scenario == \"PT\"\n",
    "      or dataset_config.scenario == \"MLCC\"\n",
    "      )\n",
    "fig_dir = f\"../figures/{dataset_config.scenario}\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(fig_dir)\n",
    "    print(f\"Directory {fig_dir} created \") \n",
    "except FileExistsError:\n",
    "    print(f\"Directory {fig_dir} already exists replacing files in this notebook\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "file_name_test = \"../data/\" + dataset_config.scenario+ \"/test_data.txt\"\n",
    "X_test,Y_test = dataset.get_functional_test_data(file_name_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "file_name_train = \"../data/\" + dataset_config.scenario+ \"/train_data.txt\"\n",
    "X_train,Y_train = dataset.get_functional_train_data(file_name_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "random_seed = 1985\n",
    "if dataset_config.scenario == \"MLCC\":\n",
    "    exp_config = config.Config(\n",
    "        model=config.ModelConfig(activation=\"elu\", lr_gen=0.0001, lr_disc=0.0005, dec_gen=0, dec_disc=0, \n",
    "                                 optim_gen=\"Adam\", optim_disc=\"Adam\", z_input_size=1, random_seed=random_seed),\n",
    "        training=config.TrainingConfig(n_epochs=500, batch_size=100, n_samples=50),\n",
    "        dataset=dataset_config,\n",
    "        run=config.RunConfig(save_fig=1)\n",
    "    )  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Unstandardized regression coefficient: \n",
      "[ 5.16265980e+02 -5.93944373e+03  3.15860370e+03 -1.34158736e+04\n",
      "  1.26865032e+04  1.49033300e+01  1.26763000e+00 -1.69634700e+01\n",
      "  1.58286887e+03  2.22348900e+01  7.31887390e+02 -8.24578380e+02]\n",
      "normal coefficient: \n",
      "120120.5083\n",
      "Standardized regression coefficient: \n",
      "[ 0.0989  -0.656    0.08608 -0.42259  0.37176  0.25209  0.66808 -0.11532\n",
      "  0.99639  0.12254  0.78234 -0.06253]\n",
      "normal coefficient: \n",
      "0.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "coef = sample.get_sta_reg_cov(X_train,Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The importance for every dimension:\n",
      "[0.005807103724392776, 0.08056379800289575, 0.027708178275372558, 0.029279516948187895, 0.06921072266530037, 0.1222271387246593, 0.11319916571268794, 0.04157214482892202, 0.12625181040975142, 0.06501790211941245, 0.3118271249994784, 0.0073353935889390945]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#elif dataset_config.scenario == \"MLCC\":\n",
    "     #imp = RelativeImportance.relativeImp_MLCC()\n",
    "imp = [0.005807103724392776, 0.08056379800289575, 0.027708178275372558, 0.029279516948187895, 0.06921072266530037, 0.1222271387246593, 0.11319916571268794, 0.04157214482892202, 0.12625181040975142, 0.06501790211941245, 0.3118271249994784, 0.0073353935889390945]\n",
    "#imp = list(imp.values())\n",
    "print(\"The importance for every dimension:\")\n",
    "print(imp)\n",
    "\n",
    "#os.exist(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Euclidean distance in x domain：\n",
      "minist dist:\n",
      "66.461\n",
      "maxist imp:\n",
      "0.3118271249994784\n",
      "The original length of the smaple: \n",
      "[ 1.23769 17.17089  5.90556  6.24046 14.75117 26.05077 24.1266   8.86044\n",
      " 26.90857 13.85753 66.461    1.56342]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "length, max_dist = sample.get_sample_length(X_train,imp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The value area of x in the sample is between 2.7 and 3.3in the dimension of No. 0\n",
      "The value area of x in the sample is between 1.83 and 2.15in the dimension of No. 1\n",
      "The value area of x in the sample is between 0.92 and 1.0in the dimension of No. 2\n",
      "The value area of x in the sample is between 0.41 and 0.5in the dimension of No. 3\n",
      "The value area of x in the sample is between 0.0 and 0.08in the dimension of No. 4\n",
      "The value area of x in the sample is between 1262.0 and 1307.0in the dimension of No. 5\n",
      "The value area of x in the sample is between 10232.0 and 11750.0in the dimension of No. 6\n",
      "The value area of x in the sample is between 22.0 and 41.0in the dimension of No. 7\n",
      "The value area of x in the sample is between -75.6 and -73.5in the dimension of No. 8\n",
      "The value area of x in the sample is between 40.4 and 54.0in the dimension of No. 9\n",
      "The value area of x in the sample is between -9.0 and -5.2in the dimension of No. 10\n",
      "The value area of x in the sample is between 0.824 and 1.03in the dimension of No. 11\n",
      "The full length of every dimension:\n",
      "[   0.6      0.32     0.08     0.09     0.08    45.    1518.      19.\n",
      "    2.1     13.6      3.8      0.206]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_min = np.amin(X_train, axis=0)\n",
    "x_max = np.amax(X_train, axis=0)\n",
    "L = sample.get_x_len(x_min, x_max)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The number of diversions of the 0th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 1th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 2th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 3th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 4th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 5th dimension is: 2\n",
      "2\n",
      "The number of diversions of the 6th dimension is: 63\n",
      "63\n",
      "The number of diversions of the 7th dimension is: 3\n",
      "3\n",
      "The number of diversions of the 8th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 9th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 10th dimension is: 1\n",
      "1\n",
      "The number of diversions of the 11th dimension is: 1\n",
      "1\n",
      "总的样方分割数为：\n",
      "378\n",
      "分割数：\n",
      "[ 1  1  1  1  1  2 63  3  1  1  1  1]\n",
      "样方的大小：\n",
      "[ 1.23769 17.17089  5.90556  6.24046 14.75117 26.05077 24.1266   8.86044\n",
      " 26.90857 13.85753 66.461    1.56342]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "n_sample,length = sample.divide_sample2(length, L, 300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "第0维度，最小的x为2.7\n",
      "第0维度的中心值有：\n",
      "[3.31884]\n",
      "第1维度，最小的x为1.83\n",
      "第1维度的中心值有：\n",
      "[10.41544]\n",
      "第2维度，最小的x为0.92\n",
      "第2维度的中心值有：\n",
      "[3.87278]\n",
      "第3维度，最小的x为0.41\n",
      "第3维度的中心值有：\n",
      "[3.53023]\n",
      "第4维度，最小的x为0.0\n",
      "第4维度的中心值有：\n",
      "[7.37558]\n",
      "第5维度，最小的x为1262.0\n",
      "第5维度的中心值有：\n",
      "[1275.02538, 1301.07616]\n",
      "第6维度，最小的x为10232.0\n",
      "第6维度的中心值有：\n",
      "[10244.0633, 10268.1899, 10292.3165, 10316.4431, 10340.5697, 10364.6963, 10388.8229, 10412.9495, 10437.0761, 10461.2027, 10485.3293, 10509.4559, 10533.5825, 10557.7091, 10581.8357, 10605.9623, 10630.0889, 10654.2155, 10678.3421, 10702.4687, 10726.5953, 10750.7219, 10774.8485, 10798.9751, 10823.1017, 10847.2283, 10871.3549, 10895.4815, 10919.6081, 10943.7347, 10967.8613, 10991.9879, 11016.1145, 11040.2411, 11064.3677, 11088.4943, 11112.6209, 11136.7475, 11160.8741, 11185.0007, 11209.1273, 11233.2539, 11257.3805, 11281.5071, 11305.6337, 11329.7603, 11353.8869, 11378.0135, 11402.1401, 11426.2667, 11450.3933, 11474.5199, 11498.6465, 11522.7731, 11546.8997, 11571.0263, 11595.1529, 11619.2795, 11643.4061, 11667.5327, 11691.6593, 11715.7859, 11739.9125]\n",
      "第7维度，最小的x为22.0\n",
      "第7维度的中心值有：\n",
      "[26.43022, 35.29066, 44.1511]\n",
      "第8维度，最小的x为-75.6\n",
      "第8维度的中心值有：\n",
      "[-62.14572]\n",
      "第9维度，最小的x为40.4\n",
      "第9维度的中心值有：\n",
      "[47.32876]\n",
      "第10维度，最小的x为-9.0\n",
      "第10维度的中心值有：\n",
      "[24.2305]\n",
      "第11维度，最小的x为0.824\n",
      "第11维度的中心值有：\n",
      "[1.60571]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "dim = len(X_train[0])\n",
    "gen_x = sample.gen_x_center(dim,length,n_sample, x_min)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "样方中心点：\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "gen_sample_point = sample.gen_product2(gen_x)\n",
    "print(\"样方中心点：\")\n",
    "gen_sample_point = np.array(gen_sample_point)\n",
    "#print(gen_sample_point)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "over\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "xlimit = []\n",
    "for index in range(len(n_sample)):\n",
    "    l = []\n",
    "    for i in range(n_sample[index]):\n",
    "        x = x_min[index] + i * length[index]\n",
    "        l.append(x)\n",
    "    l.append(x_min[index] + n_sample[index] * length[index])\n",
    "    xlimit.append(l)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "sample_list = []\n",
    "xlim_list = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "over\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "x_value = []\n",
    "for index in range(dim):\n",
    "    xl = []\n",
    "    for i in range(len(X_train)):\n",
    "        x = X_train[i][index]\n",
    "        r = 0\n",
    "        for xi in xl:\n",
    "            if xi == x:\n",
    "                r = 1\n",
    "        if r == 0:\n",
    "            xl.append(x)\n",
    "    x_value.append(xl)\n",
    "    \n",
    "x_value_ori = copy.deepcopy(x_value)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "over\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "XLim.con_s(gen_sample_point, sample_list, dim, xlimit)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "over\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "XLim.con_sample(xlim_list, length, x_min, dim, n_sample)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "over\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "XLim.sample_feature(xlim_list, sample_list, x_value)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "XLim.add_xvalue(xlim_list)\n",
    "#os.exist(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "x_com, x_add = Generation.get_x_com(X_train, dim, x_value, x_value_ori)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "E_dist = Generation.E_dist(x_com)\n",
    "#os.exist(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "over\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "gen_x = []\n",
    "discard_list = []\n",
    "Generation.gen_x_sample2(sample_list, gen_x, dim, x_max, x_min, n_sample, X_train)\n",
    "#gen_x_cross = sample.gen_product(x_value)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "over\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "plot_xlim = copy.deepcopy(xlimit)\n",
    "for index in range(dim):\n",
    "    i = len(plot_xlim[index])\n",
    "    plot_xlim[index][i-1] = x_max[index]\n",
    "print(\"over\")        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "gen_x_checked = []\n",
    "XLim.check2(sample_list, xlim_list, gen_x_checked, discard_list, gen_x)\n",
    "XLim.sample_attri(sample_list, X_train, gen_x_checked, Y_train)\n",
    "XLim.xl_attri(xlim_list, X_train, gen_x_checked)\n",
    "gen_x = np.array(gen_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Generator_input_z (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Generator_input_y (InputLayer)  (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 50)           100         Generator_input_z[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 50)           100         Generator_input_y[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100)          0           dense_10[0][0]                   \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 90)           9090        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 80)           7280        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 70)           5670        dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 80)           5680        dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 80)           6480        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 80)           6480        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 12)           972         dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 41,852\n",
      "Trainable params: 41,852\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Discriminator_input_x (InputLay (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Discriminator_input_y (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           260         Discriminator_input_x[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           40          Discriminator_input_y[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 40)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 80)           3280        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 60)           4860        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 60)           3660        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 70)           4270        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 70)           4970        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            71          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 42,822\n",
      "Trainable params: 21,411\n",
      "Non-trainable params: 21,411\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "D:\\CondaEnv\\netSVGpython36\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning:\n",
      "\n",
      "Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f7e5393fb6c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true = cgan.train(X_train_scaled, Y_train, \n\u001b[0;32m      9\u001b[0m                                                                               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                                                                               batch_size=exp_config.training.batch_size)\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mypred_gan_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\netSVG\\models\\cgan_model_real.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, xtrain, ytrain, epochs, batch_size, verbose)\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mdLossErr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m             \u001b[0mdLossReal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_loss_real\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[0mdLossFake\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'd_loss' referenced before assignment"
     ],
     "ename": "UnboundLocalError",
     "evalue": "local variable 'd_loss' referenced before assignment",
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "cgan = cgan_model_real.CGAN(exp_config)\n",
    "d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true = cgan.train(X_train_scaled, Y_train, \n",
    "                                                                              epochs=exp_config.training.n_epochs,\n",
    "                                                                              batch_size=exp_config.training.batch_size)\n",
    "\n",
    "ypred_gan_test = cgan.predict(X_test_scaled)\n",
    "gen_y_cross = cgan.predict(gen_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plotting.plots(d_loss_err, d_loss_true, d_loss_fake, g_loss_err, g_pred, g_true, fig_dir, exp_config.run.save_fig)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ypred_mean_gan_test, ypred_median_gan_test, ypred_gan_sample_test = cgan.sample(X_test_scaled, \n",
    "                                                                                exp_config.training.n_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ypred_mean_gan_train, ypred_median_gan_train, ypred_gan_sample_train = cgan.sample(X_train_scaled, \n",
    "                                                                                   exp_config.training.n_samples)\n",
    "\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "XLim.add_y2(sample_list, cgan, scaler)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "point_list = []\n",
    "Point.con_point(gen_x, gen_y_cross, point_list)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for sample in sample_list:\n",
    "    for index in range(len(sample.gen_xlist)):\n",
    "        for point in point_list:\n",
    "            r = -1\n",
    "            for i in range(dim):\n",
    "                if point.x[i] != sample.gen_xlist[index][i]:\n",
    "                    r = 0\n",
    "                    break\n",
    "            if r == -1:\n",
    "                sample.points.append(point)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "qrX = X_train\n",
    "qrX = sm.add_constant(qrX[0:])\n",
    "qr = sm.QuantReg(Y_train.reshape(-1,1),qrX)\n",
    "res = qr.fit(q=.2)\n",
    "print(res.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quantiles = np.arange(.05, .96, .1)\n",
    "quantiles = np.around(quantiles, decimals=3)\n",
    "def fit_model(q):\n",
    "    res = qr.fit(q=q)\n",
    "    return q, np.around(res.params,decimals=  4)\n",
    "\n",
    "models = []\n",
    "\n",
    "for x in quantiles:\n",
    "    q, param = fit_model(x)\n",
    "    model = QrModels.QrModels(q, param[0], param[1:])\n",
    "    models.append(model)\n",
    "\n",
    "for model in models:\n",
    "    print(str(model.q)+'\\t'+str(model.a)+'\\t'+str(model.param))\n",
    "\n",
    "ols = sm.OLS(Y_train.reshape(-1,1),qrX).fit()\n",
    "           \n",
    "for ol in ols.params:\n",
    "    print(str(ol))\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_quantile = [15676.750,16559.600,16657.000,17030.200,17143.350,17286.050,17342.350,17843.250,18193.950,18403.250]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for xv in x_value:\n",
    "    xv.sort()\n",
    "for xv in x_value_ori:\n",
    "    xv.sort()\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vir_xpoint = []\n",
    "vir_ypoint = []\n",
    "del_list = []\n",
    "QRselection.qr_selection2(xlim_list, models, vir_xpoint, vir_ypoint, y_quantile, ols, x_value_ori,\n",
    "                 n_sample, X_train, Y_train, sample_list, point_list, x_value)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "for point in point_list:\n",
    "    if point.checked == 1:\n",
    "        i += 1\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from hpelm import ELM\n",
    "elm_old = ELM(12, 1)\n",
    "elm_old.add_neurons(51, \"sigm\")\n",
    "#elm.add_neurons(10, \"rbf_l2\")\n",
    "elm_old.train(X_train, Y_train, \"LOO\")\n",
    "y_predict_old = elm_old.predict(X_test)\n",
    "\n",
    "elm_new = ELM(12, 1)\n",
    "elm_new.add_neurons(51, \"sigm\")\n",
    "#elm.add_neurons(10, \"rbf_l2\")\n",
    "add_x_train = dataset.add_train(X_train, np.array(vir_xpoint))\n",
    "add_y_train = dataset.add_train(Y_train, np.array(vir_ypoint))\n",
    "elm_new.train(np.array(vir_xpoint), np.array(vir_ypoint), \"LOO\")\n",
    "y_predict_new = elm_new.predict(X_test)\n",
    "\n",
    "test_list = []\n",
    "for i in range(len(X_test)):\n",
    "    test_point = Point.TestPoint(X_test[i], Y_test[i], y_predict_old[i], y_predict_new[i])\n",
    "    test_list.append(test_point)\n",
    "print(\"over\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plotting.plot_erro2(test_list, exp_config, fig_dir, \"vir_erro\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mae_old, mae_new = Measure.mae2(test_list)\n",
    "mse_old, mse_new = Measure.mse2(test_list)\n",
    "mape_old, mape_new = Measure.mape2(test_list)\n",
    "print(\" all test point\")\n",
    "print(mae_old)\n",
    "print(mae_new)\n",
    "print(mse_old)\n",
    "print(mse_new)\n",
    "print(mape_old)\n",
    "print(mape_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(\"../figures/MLCC/vx_data.txt\", np.array(vir_xpoint),fmt='%.8f',delimiter=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.savetxt(\"../figures/MLCC/vy_data.txt\", np.array(vir_ypoint),fmt='%.8f',delimiter=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GAN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}